# OpenAI API 配置
# 复制此文件为 .env.local 并填入你的 API Key

# OpenAI API Key（单个，必需）
# 获取方式：https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# OpenAI API Keys（多个，可选，用于负载均衡提升速度）
# 多个 API Key 用逗号分隔，例如：sk-key1,sk-key2,sk-key3
# 如果设置了 OPENAI_API_KEYS，将优先使用它进行负载均衡
# 注意：使用多个 API Key 可以绕过速率限制，提升并发性能
# OPENAI_API_KEYS=sk-key1,sk-key2,sk-key3

# OpenAI API Base URL（可选，默认使用官方地址）
# 如果使用代理或兼容 OpenAI API 的服务，可以设置自定义地址
# OPENAI_BASE_URL=https://api.openai.com/v1

# 使用的模型（可选，默认：gpt-4o-mini）
# 推荐模型：
# - gpt-4o-mini: 性价比高，速度快
# - gpt-4o: 更强的能力
# - gpt-4-turbo: 平衡性能和成本
# - gpt-3.5-turbo: 更便宜但能力较弱
OPENAI_MODEL=gpt-4o-mini

# 最大生成 token 数（可选，默认：2000）
# 建议值：1500-4000，根据你的需求调整
OPENAI_MAX_TOKENS=2000

# 温度参数（可选，默认：0.7）
# 范围：0.0-2.0
# 较低值（0.1-0.3）：更确定性和一致性的输出
# 中等值（0.7-0.9）：平衡创造性和准确性
# 较高值（1.0-2.0）：更有创造性和随机性
OPENAI_TEMPERATURE=0.7

# ============================================
# 主持人专用 API Key（可选）
# ============================================
# 如果设置了 MODERATOR_API_KEY，主持人总结将使用独立的 Key
# 如果未设置，将回退使用上面的 OPENAI_API_KEY / OPENAI_API_KEYS
# MODERATOR_API_KEY=sk-your-moderator-key-here

# ============================================
# 认证配置
# ============================================
# JWT 签名密钥（生产环境必须设置，至少 32 位随机字符串）
# JWT_SECRET=your-random-jwt-secret-at-least-32-chars

# Access Token 有效期（默认 2h）
# AUTH_TOKEN_EXPIRES_IN=2h

# Refresh Token 有效期（默认 7d）
# AUTH_REFRESH_TOKEN_EXPIRES_IN=7d

# ============================================
# PostgreSQL 数据库（生产环境推荐）
# ============================================
# 配置后将自动启用：
# - DatabaseSessionStore（会话持久化到数据库）
# - DatabaseAuthProvider（用户数据存储到数据库）
# - UsageLog（LLM 调用使用量统计）
#
# 初始化：npx prisma migrate dev --name init
# DATABASE_URL=postgresql://user:password@localhost:5432/multiagent?schema=public

# ============================================
# Redis 配置（可选，多实例缓存）
# ============================================
# REDIS_URL=redis://localhost:6379

# ============================================
# 日志配置
# ============================================
# 日志级别：debug, info, warn, error（默认：开发 debug / 生产 info）
# LOG_LEVEL=info

# ============================================
# 频率控制
# ============================================
# 每个 API Key 每分钟最大请求数（默认 60）
# RATE_LIMIT_RPM_PER_KEY=60

# 每个用户每分钟最大请求数（默认 10）
# RATE_LIMIT_RPM_PER_USER=10

# 全局最大并发 LLM 调用数（默认 50）
# MAX_CONCURRENT_LLM_CALLS=50

# ============================================
# 部署配置（生产环境）
# ============================================

# 前端 API 基础地址（前端部署到 Vercel 时设置为后端 ALB 域名）
# 本地开发不设此项（同源，相对路径即可）
# NEXT_PUBLIC_API_BASE_URL=https://api.yourapp.com

# CORS 允许的来源（后端部署到 AWS 时设置为前端域名，多个逗号分隔）
# 本地开发不设此项（同源不需要 CORS）
# CORS_ALLOWED_ORIGINS=https://yourapp.vercel.app,https://www.yourapp.com

# 是否启用 standalone 构建模式（Docker 构建时设为 true）
# BUILD_STANDALONE=true

# 数据库连接池大小（默认 10）
# DB_POOL_MAX=10

# 应用版本号（健康检查端点返回）
# APP_VERSION=1.0.0

# ============================================
# 豆包 API 配置（可选）
# ============================================
# 如果设置了豆包 API Key，前两个 Agent（涨停敢死队长、价值投资苦行僧）和总结将使用豆包 API
# 其他 Agent 将继续使用上面配置的 OpenAI/DeepSeek API

# 豆包 API Key（可选）
# DOUBAO_API_KEY=your-doubao-api-key-here

# 豆包 API Base URL（可选，默认：https://ark.cn-beijing.volces.com/api/v3）
# DOUBAO_BASE_URL=https://ark.cn-beijing.volces.com/api/v3

# 豆包模型名称（可选，默认：doubao-pro-4k）
# 可选模型：doubao-pro-4k, doubao-lite-4k, doubao-pro-32k 等
# DOUBAO_MODEL=doubao-pro-4k
