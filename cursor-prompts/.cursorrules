You are helping build a Web app: "multi-agent stock discussion system".

Tech stack:
- Next.js (App Router) + TypeScript + React
- Backend logic implemented via Next.js Route Handlers in /app/api
- LLM access is abstracted behind a simple client (e.g. LLMClient)

Business context:
- Users create a "discussion session" about a stock-related topic.
- They choose 3–4 preset Agents:
  - 涨停敢死队长（短线游资之王）
  - 价值投资苦行僧（巴菲特的中国门徒）
  - 量化狙击手（华尔街归来的算法之神）
  - 草根股神老王（菜市场到千万资产的民间传奇）

Discussion flow:
- **Round 1 (First Round)**:
  - Each Agent generates their main speech about the topic (system prompt = the Agent role; user prompt = first round speech template).
  - No reviews/critiques in the first round.
  - Generate a structured JSON round summary (consensus, conflicts, insights, nextRoundSuggestions).
- **Round 2+ (Subsequent Rounds)**:
  - Each Agent must analyze disagreements from the previous round and respond directly to another Agent.
  - Each Agent's speech must:
    1. Find at least one Agent with conflicting views from the previous round
    2. Explicitly @mention that Agent (format: @Agent名称)
    3. Summarize the disagreement point
    4. Respond to that disagreement point (can counter or acknowledge)
    5. Be limited to 200 characters
    6. **Must NOT express overall views on the topic** - only respond to the disagreement
  - System prompt emphasizes: "找出与你观点有分歧的其他Agent，并明确@对方，总结分歧点，然后针对该分歧观点进行回应"
  - Generate a structured JSON round summary after all Agents have spoken.
- At the end, generate a session summary based on all rounds.

Existing prompts:
- Agent role system prompts are defined in /prompts/agents.ts as AgentConfig.systemPrompt.
- First round speech and review user prompts are defined in /prompts/roundAgentPrompts.ts.
- Subsequent rounds (Round 2+) speech user prompts are defined in /prompts/subsequentRoundAgentPrompts.ts (uses disagreement analysis format).
- Round summary prompts are defined in /prompts/roundSummaryPrompts.ts.
- Session summary prompts are defined in /prompts/sessionSummaryPrompts.ts.

What you should do when I ask for code:
- Use the existing prompt templates and types from /prompts/*.
- Implement functions that:
  - Build concrete prompts by filling {{ }} placeholders with runtime data.
  - Call an abstract LLM client (e.g. LLMClient.generate(system, user)).
  - Parse JSON outputs robustly (try/catch + fallback).
- Keep everything strongly typed with TypeScript, avoid any.
- For Round 2+ speeches, ensure the prompt enforces @mentioning and disagreement-focused responses.

Only work on this repository, and assume it is a Next.js TypeScript project.
